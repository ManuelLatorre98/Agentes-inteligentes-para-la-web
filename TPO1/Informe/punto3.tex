\section{Ejercicio 3}
Un agente deberia tener las siguientes cualidades para navegar la Web Semántica
\begin{itemize}
  \item El agente debe ser capaz de comprender cada declaración que recopila. Una forma de lograrlo es entendiendo los términos comunes y las relaciones que se utilizan para crear estas declaraciones, lo cual implica comprender los datos en formato RDF ya que proporcionan un modelo estandar para representar información semántica en la web, utilizando tripletas sujetos-predicados-objetos para expresar relaciones entre entidades. El agente debe ser capaz de interpretar dichas tripletas y completar la estructura y el significado de los datos RDF

  \item El agente debe ser capaz de realizar razonamientos basados en su comprensión de los términos y las relaciones comunes. Por ejemplo, al saber que los recursos A y B tienen la misma dirección de correo electrónico y considerar el conocimiento expresado por los términos y las relaciones comunes, debería ser capaz de concluir que A y B son en realidad el mismo recurso. Para esto se utilizan lógicas descriptivas ya que le dan la capacidad al agente de inferir nuevas conclusiones a partir de información disponible en las ontologías y los datos RDF. Estas lógicas proporcionan un marco formal para realizar inferencias y deducciones, lo que permite al agente obtener un mayor nivel de comprensión y conocimiento de los datos semánticos

  \item El agente debe ser capaz de procesar algunas consultas comunes que se realicen sobre las declaraciones que ha recopilado. Ya que, si no se proporciona una interfaz de consulta, las declaraciones recopiladas no serán de utilidad alguna. Aquí entra en juego SPARQL permitiéndole al agente ejecutar consultas sobre los datos RDF para obtener información especifica, brindándole la capacidad de buscar y filtrar datos según ciertos criterios.
  
  \item El agente debería ser capaz de utilizar ontologías para comprender la semántica de los datos y realizar razonamiento lógico sobre ellos. Las ontologías son modelos conceptuales que describen las relaciones y propiedades entre los diferentes elementos de un dominio de conocimiento, proporcionando una estructura formal para representar dicho conocimiento y permitiendo al agente inferir nuevas relaciones y conclusiones a partir de la información disponible.
\end{itemize}

\subsection{Web 2.0 vs Web Semantica}
Comparado con un agente para la Web 2.0, un agente para la Web Semántica tiene capacidades más avanzadas en términos de interpretación y comprensión del contenido. Mientras que un agente para la Web 2.0 generalmente se centra en la extracción de información basada en palabras clave y la búsqueda de contenido relevante, un agente para la Web Semántica puede entender la semántica subyacente de los datos y realizar inferencias lógicas sobre ellos. Esto permite al agente obtener un mayor nivel de conocimiento y comprensión, y proporciona la capacidad de realizar consultas más sofisticadas y contextualmente más relevantes. Además, un agente para la Web Semántica puede aprovechar la estructura y el significado de las ontologías para navegar y descubrir información de manera más precisa y eficiente, mientras que un agente para la Web 2.0 se basa principalmente en algoritmos de búsqueda de texto plano.

Un ejemplo claro donde se pueden ver las ventajas de la Web semantica sobre la Web 2.0 es en las implementaciones de ``mashups''. Un ``mashup'' es una aplicación web que recopila datos estructurados producidos por terceros a traves de APIs ofrecidas por dichos terceros, y procesa los datos de alguna manera para luego representarlos a los usuarios de una forma que difiere de su apariencia original. Normalmente, una aplicación de mashup mejora la presentación visual de los datos o ofrece un valor añadido a sus usuarios al combinar datos de diferentes fuentes, o ambas cosas. Este concepto esta mas relacionado con la Web 2.0, donde cada vez mas sitios web esconden su datos a traves de sus APIs. 

Un ``mashup'' implementado en Web 2.0 presenta la siguientes desventajas y complicaciones:

\begin{itemize}
  \item Limitada escalabilidad: La construcción de un ``mashup'' basado en APIs requiere aprender cada conjunto de APIs de diferentes proveedores, lo que implica un proceso constante de aprendizaje. Además, cada vez que haya un nuevo proveedor, será necesario aprender un nuevo conjunto de APIs. Por lo tanto, la construcción y mantenimiento de este tipo de ``mashup'' no es escalable y puede resultar costoso.
  \item Cobertura limitada: Un ``shopbot'' de una tienda digital, por ejemplo, solo puede comprender las APIs que se han programado para que entienda. No puede explorar por sí mismo, lo que limita la cobertura de datos. Cualquier decisión basada en este ``shopbot''probablemente no sea óptima debido a la limitada cobertura de datos.
  \item Desconexión con los proveedores de datos: Una vez que el ``shopbot'' recupera y consume los datos, se pierde el enlace entre este y el proveedor de datos original. Los usuarios no pueden regresar al sitio original que proporcionó los datos. Incluso si se incluyen enlaces que direccionan de vuelta a los proveedores de datos, estos enlaces suelen ser superficiales y no pueden llevar a ubicaciones precisas de los componentes de datos específicos. Esto limita la capacidad del usuario para aprovechar ofertas especiales u otras características ofrecidas en el sitio original.
\end{itemize}

En cambio con Web semantica a traves del uso de datos enlazados (\textit{Linked Data}) se obtendrán los siguientes resultados:
\begin{itemize}
  \item Buena escalabilidad del método en sí mismo: Bajo la Web de Datos Enlazados, los datos estructurados se expresan utilizando grafos y estándares RDF, que son un conjunto de estándares comunes a todos los sitios. Esto hace que la construcción y el mantenimiento de un mashup sean escalables, ya que no es necesario aprender constantemente nuevas APIs.
  \item Cobertura ilimitada de conjuntos de datos: A diferencia de los mashups de Web 2.0, las aplicaciones de Linked Data (Web semántica) operan sobre un espacio de datos global y sin límites. Esto les permite proporcionar respuestas más completas a medida que aparecen nuevas fuentes de datos en la Web.
  \item Enlaces cruciales para volver a los proveedores de datos: En los mashups de Linked Data, todos los elementos (recursos) se identifican mediante URIs controladas por el proveedor de datos. Si un usuario busca una de estas URIs, puede ser direccionado de vuelta al proveedor de datos original, quien puede proporcionar contenido adicional para dirigir el tráfico entrante. Esta capacidad de enlace es una diferencia clave entre los mashups de Web 2.0 y los mashups de Linked Data, y es donde reside el potencial valor comercial.
  \item Los mashups de Linked Data también ofrecen a los usuarios la posibilidad de enlazar casi ilimitadamente con otros recursos. Cada elemento en el mashup se identifica mediante una URI, que puede estar vinculada a otros recursos en otros conjuntos de datos. Estos enlaces también están tipificados, lo que permite al usuario seguirlos y visitar recursos específicos en otros conjuntos de datos. Esta capacidad de enlace ilimitado ofrece un valor significativo.
\end{itemize}
